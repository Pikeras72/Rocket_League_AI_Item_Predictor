{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "lOwotflhVYP5"
      ],
      "authorship_tag": "ABX9TyNBzyj0JQkt7kDh575uHawc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pikeras72/Rocket_League_AI_Item_Predictor/blob/main/notebook/RL_Item_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rocket League - AI Item Predictor\n",
        "\n",
        "In this notebook you will be able to ask the model for a prediction of any rocket league item in the game.\n",
        "\n",
        "Will it guess correctly...? **Let's find out!**\n",
        "\n",
        "Made by ***Diego Ruiz Piqueras***"
      ],
      "metadata": {
        "id": "Q_mPRKDkvRKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the dataset"
      ],
      "metadata": {
        "id": "mTr11wDXQ3KE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First step is to have the required data in order to train the model.\n",
        "\n",
        "We will start by obtaining the **Rocket League items dataset** and unzipping it into the '/content/' folder of this notebook."
      ],
      "metadata": {
        "id": "pUQ1OBtpzA9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import gdown\n",
        "\n",
        "# URL to download the Google Drive file containing the dataset (RL_items_dataset.zip)\n",
        "url = \"https://drive.google.com/uc?id=19VqLlvyDtLzTx0ZajO1Hcmgr5zICF3pU\"\n",
        "output = \"RL_items_dataset.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Unzip the zip file in the /content/ folder\n",
        "import zipfile\n",
        "with zipfile.ZipFile(output, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "print(\"Dataset correctly downloaded and unzipped!\")"
      ],
      "metadata": {
        "id": "a-NwjCXC_Mex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our dataset unziped and located, we will **assign the directory names** of each folder **as the variable's labels inside those directories.**\n",
        "\n",
        "In other words, all the images in the wheels directory will be labeled as wheels, all the images in the bodies directory will be labeled as bodies, etc."
      ],
      "metadata": {
        "id": "hjQFoQ84ysyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/RL_items_dataset/train'\n",
        "\n",
        "labels = [\"antennas\", \"anthems\", \"banners\", \"bodies\", \"boosts\", \"borders\", \"decals\", \"paints\", \"toppers\", \"trails\", \"wheels\"]\n",
        "\n",
        "# We get all the directories inside the training directory\n",
        "antennas_dir = os.path.join(base_dir, labels[0])\n",
        "anthems_dir = os.path.join(base_dir, labels[1])\n",
        "banners_dir = os.path.join(base_dir, labels[2])\n",
        "bodies_dir = os.path.join(base_dir, labels[3])\n",
        "boosts_dir = os.path.join(base_dir, labels[4])\n",
        "borders_dir = os.path.join(base_dir, labels[5])\n",
        "decals_dir = os.path.join(base_dir, labels[6])\n",
        "paints_dir = os.path.join(base_dir, labels[7])\n",
        "toppers_dir = os.path.join(base_dir, labels[8])\n",
        "trails_dir = os.path.join(base_dir, labels[9])\n",
        "wheels_dir = os.path.join(base_dir, labels[10])\n",
        "\n",
        "# We calculate the total number of elements inside the training directory\n",
        "total_num = len(os.listdir(antennas_dir))+len(os.listdir(anthems_dir))+len(os.listdir(banners_dir))+len(os.listdir(bodies_dir))+len(os.listdir(boosts_dir))+len(os.listdir(borders_dir))+len(os.listdir(decals_dir))+len(os.listdir(paints_dir))+len(os.listdir(toppers_dir))+len(os.listdir(trails_dir))+len(os.listdir(wheels_dir))\n",
        "\n",
        "# We print the number of elements in each subdirectory\n",
        "print('total training images:', total_num,\"\\n\")\n",
        "print('total training antennas images:', len(os.listdir(antennas_dir)))\n",
        "print('total training anthems images:', len(os.listdir(anthems_dir)))\n",
        "print('total training banners images:', len(os.listdir(banners_dir)))\n",
        "print('total training bodies images:', len(os.listdir(bodies_dir)))\n",
        "print('total training boosts images:', len(os.listdir(boosts_dir)))\n",
        "print('total training borders images:', len(os.listdir(borders_dir)))\n",
        "print('total training decals images:', len(os.listdir(decals_dir)))\n",
        "print('total training paints images:', len(os.listdir(paints_dir)))\n",
        "print('total training toppers images:', len(os.listdir(toppers_dir)))\n",
        "print('total training trails images:', len(os.listdir(trails_dir)))\n",
        "print('total training wheels images:', len(os.listdir(wheels_dir)))\n",
        "\n",
        "# Here we obtain a list containing the names of the entries for each directory.\n",
        "antennas_files = os.listdir(antennas_dir)\n",
        "anthems_files = os.listdir(anthems_dir)\n",
        "banners_files = os.listdir(banners_dir)\n",
        "bodies_files = os.listdir(bodies_dir)\n",
        "boosts_files = os.listdir(boosts_dir)\n",
        "borders_files = os.listdir(borders_dir)\n",
        "decals_files = os.listdir(decals_dir)\n",
        "paints_files = os.listdir(paints_dir)\n",
        "toppers_files = os.listdir(toppers_dir)\n",
        "trails_files = os.listdir(trails_dir)\n",
        "wheels_files = os.listdir(wheels_dir)"
      ],
      "metadata": {
        "id": "RSBd8OQey-GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "total training images: 1584\n",
        "\n",
        "total training antennas images: 204\n",
        "total training anthems images: 53\n",
        "total training banners images: 208\n",
        "total training bodies images: 115\n",
        "total training boosts images: 138\n",
        "total training borders images: 88\n",
        "total training decals images: 208\n",
        "total training paints images: 79\n",
        "total training toppers images: 208\n",
        "total training trails images: 75\n",
        "total training wheels images: 208\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "T5YnIqFfPkG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Completed!**\n",
        "\n",
        "Now that we have all the elements in lists, we'll **look at some examples** of what some images look like:"
      ],
      "metadata": {
        "id": "yc8FcEud2Vc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from random import seed\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "nrows = 4\n",
        "ncols = 6\n",
        "\n",
        "# Between 0 and 53 in order to show 'anthems' images in every execution\n",
        "index = randint(0,53)\n",
        "\n",
        "# We pick 2 images for each type of item and we show them with matplotlib.pyplot\n",
        "next_antennas = [os.path.join(antennas_dir, fname) for fname in antennas_files[index-2:index]]\n",
        "\n",
        "next_anthems = [os.path.join(anthems_dir, fname) for fname in anthems_files[index-2:index]]\n",
        "\n",
        "next_banners = [os.path.join(banners_dir, fname) for fname in banners_files[index-2:index]]\n",
        "\n",
        "next_bodies = [os.path.join(bodies_dir, fname) for fname in bodies_files[index-2:index]]\n",
        "\n",
        "next_boosts = [os.path.join(boosts_dir, fname) for fname in boosts_files[index-2:index]]\n",
        "\n",
        "next_borders = [os.path.join(borders_dir, fname) for fname in borders_files[index-2:index]]\n",
        "\n",
        "next_decals = [os.path.join(decals_dir, fname) for fname in decals_files[index-2:index]]\n",
        "\n",
        "next_paints = [os.path.join(paints_dir, fname) for fname in paints_files[index-2:index]]\n",
        "\n",
        "next_toppers = [os.path.join(toppers_dir, fname) for fname in toppers_files[index-2:index]]\n",
        "\n",
        "next_trails = [os.path.join(trails_dir, fname) for fname in trails_files[index-2:index]]\n",
        "\n",
        "next_wheels = [os.path.join(wheels_dir, fname) for fname in wheels_files[index-2:index]]\n",
        "\n",
        "for i, img_path in enumerate(next_antennas + next_anthems + next_banners + next_bodies + next_boosts + next_borders + next_decals + next_paints + next_toppers + next_trails + next_wheels):\n",
        "    ax = plt.subplot(nrows, ncols, i + 1)\n",
        "    img = Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    ax.axis('off')  # Hide axis\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "moESC4hY2ZzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to know that all the images in the dataset are **colored 220x220px** images."
      ],
      "metadata": {
        "id": "dbpmLKG-v3WB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# You want to do it by yourself? Skip this section and start building!\n",
        "\n",
        "If you just want a quick view of how it works, here I will show you a model that have been already trained with aproximately **96% accuracy**.\n",
        "\n",
        "**Give it a try!**"
      ],
      "metadata": {
        "id": "lOwotflhVYP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL to download the Google Drive file containing the model (RL_item_predictor_model.keras)\n",
        "url = \"https://drive.google.com/uc?id=17h2Ud6tOTltRKJDGLxY9N662qoOtE5aI\"\n",
        "output = \"/content/Loaded_model.keras\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "print(\"\\nModel correctly downloaded!\")"
      ],
      "metadata": {
        "id": "gP49GT_gWBaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.utils import load_img, img_to_array\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.saving.load_model(output)\n",
        "\n",
        "# Check the structure of the model!\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "EZ5r6rrx6o68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we can see how the model looks like, we can **ask for predictions**!\n",
        "\n",
        "By running this next block you will be able to upload images from your computer and see how the model classifies them.\n",
        "\n",
        "**Give it a try!**"
      ],
      "metadata": {
        "id": "_I1bHpvT9OYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # Predicting images\n",
        "  path = fn\n",
        "  img = load_img(path, target_size=(220, 220))\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classes = loaded_model.predict(images, batch_size=10)\n",
        "  predicted_class_index = np.argmax(classes)\n",
        "  print(fn)\n",
        "  print('This image is in: ['+ labels[predicted_class_index] +']')"
      ],
      "metadata": {
        "id": "5iQu7l1x9L3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Build the model by yourself\n",
        "\n",
        "**Time to shine!**\n",
        "\n",
        "This is the CNN model I have made. But you can try to change it, I am sure you can improve it!"
      ],
      "metadata": {
        "id": "oB6E6cwgeECV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers, models\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolution and MaxPooling layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(220, 220, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten layer\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dropout layer\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "# Dense layers\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "# As there are 11 different types of items in the dataset, the last Dense layer contains 11 units and Softmax activation\n",
        "model.add(layers.Dense(11, activation='softmax'))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hCQ-YfD8eMV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Image generator"
      ],
      "metadata": {
        "id": "iLQENSKpejGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will **rescale the images** in our training and validating sets and **set their input size** to 220x220px (Although the images are already 220x220px).\n"
      ],
      "metadata": {
        "id": "yLEygOaPXIit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "TRAINING_DIR = \"/content/RL_items_dataset/train\"\n",
        "training_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "VALIDATION_DIR = \"/content/RL_items_dataset/test\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# 'class_mode' is set to categorical as we have 11 different type of items\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(220,220),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# 'class_mode' is set to categorical as we have 11 different type of items\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(220,220),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "E9zCdaWHe4rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "\n",
        "\n",
        "```\n",
        "Found 1584 images belonging to 11 classes.\n",
        "Found 395 images belonging to 11 classes.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "OICesarlR-NJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compile the model"
      ],
      "metadata": {
        "id": "1vrns0b90L_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are approaching the final steps and now is turn to compile the model.\n",
        "\n",
        "Remember you can try to change **the optimizer** and **the learning rate**!"
      ],
      "metadata": {
        "id": "AFITOwLOeZLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function is set to 'categorical_crossentropy' as we have 11 different type of items\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XCRA6NVWegA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "Finally, now it is time to train the model! *(my favourite part)*\n",
        "\n",
        "I will train it for **5 epochs**.\n",
        "\n",
        "The **'steps_per_epoch'** is assigned to: Number of training images//BATCH_SIZE\n",
        "\n",
        "The **'validation_steps'** is assigned to: Number of validating images//BATCH_SIZE"
      ],
      "metadata": {
        "id": "yUNSY3N2fTsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs= 5,\n",
        "                    steps_per_epoch= 1584//BATCH_SIZE,\n",
        "                    validation_data= validation_generator,\n",
        "                    validation_steps= 395//BATCH_SIZE)"
      ],
      "metadata": {
        "id": "4WX3W5a2fYG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "After some time, our model has been **successfully trained**. Now let's see how good (or bad) our model is."
      ],
      "metadata": {
        "id": "1qCYKDzlViVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pFgDx1TCfiSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did your model work well??\n",
        "\n",
        "If you think this model is good enough you can proceed and **save it for future predictions**."
      ],
      "metadata": {
        "id": "OR2rqOaYV4ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# It is important to save the model in case of error in the notebook\n",
        "model.save(\"/content/RL_item_predictor_model.keras\")\n",
        "files.download(\"/content/RL_item_predictor_model.keras\")"
      ],
      "metadata": {
        "id": "G51Dxc7p4Wl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction time"
      ],
      "metadata": {
        "id": "IjJSIk7DWJ4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can **test this model** and see how it performs.\n",
        "\n",
        "By running this next block you will be able to upload images from your computer and see how the model classifies them.\n",
        "\n",
        "The model has not trained with [this images](https://drive.google.com/uc?id=1abiigbN2kIBtwKJ-kZWiKdXa2wl8qrTM)!\n",
        "\n",
        "**Give it a try!**"
      ],
      "metadata": {
        "id": "8AvHBXJ3WNJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # Predicting images\n",
        "  path = fn\n",
        "  img = load_img(path, target_size=(220, 220))\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  predicted_class_index = np.argmax(classes)\n",
        "  print(fn)\n",
        "  print('This image is in: ['+ labels[predicted_class_index] +']')"
      ],
      "metadata": {
        "id": "nwl-WoCcg-Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ymnGN0wzAUUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "\n",
        "//TODO"
      ],
      "metadata": {
        "id": "q9sbphh_AfD4"
      }
    }
  ]
}